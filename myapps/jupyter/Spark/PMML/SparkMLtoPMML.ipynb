{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Spark and SQL Contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.context.SQLContext at 0x7f5c1406e8d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sparkContext = SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sparkContext)\n",
    "\n",
    "sqlContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/root/spark-1.6.1-bin-fluxcapacitor/python/lib/py4j-0.9-src.zip',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.fasterxml.jackson.core_jackson-core-2.6.6.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/commons-codec_commons-codec-1.9.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.apache.httpcomponents_httpcore-4.4.4.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.6.6.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.fasterxml.jackson.core_jackson-databind-2.6.6.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/software.amazon.ion_ion-java-1.0.0.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.apache.httpcomponents_httpclient-4.5.2.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/commons-logging_commons-logging-1.1.3.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_jmespath-java-1.0.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-swf-libraries-1.11.22.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-models-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-core-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-snowball-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-applicationautoscaling-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-discovery-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-cognitoidp-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-marketplacemeteringservice-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-dms-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-gamelift-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-acm-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-api-gateway-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-iot-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-inspector-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-marketplacecommerceanalytics-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-waf-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-elasticsearch-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-devicefarm-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-codecommit-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-efs-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-directory-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-machinelearning-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-workspaces-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-ssm-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-cloudhsm-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-ecr-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-ecs-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-lambda-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-config-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-kms-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-codepipeline-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-codedeploy-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-cloudwatchmetrics-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-cloudsearch-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-autoscaling-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-ses-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-opsworks-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-kinesis-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-cloudfront-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-cloudformation-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-directconnect-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-cognitosync-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-cognitoidentity-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-events-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-logs-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-cloudwatch-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-cloudtrail-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-sns-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-dynamodb-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-ec2-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-elastictranscoder-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-elasticache-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-emr-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-elasticloadbalancingv2-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-elasticloadbalancing-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-datapipeline-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-iam-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-glacier-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-elasticbeanstalk-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-redshift-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-rds-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-sqs-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-sts-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-importexport-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-s3-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-route53-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-storagegateway-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-simpleworkflow-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-servicecatalog-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-simpledb-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-support-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/javax.xml.bind_jaxb-api-2.2.7.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/xalan_xalan-2.7.0.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/xerces_xercesImpl-2.8.0.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/xml-apis_xml-apis-1.3.03.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/javax.json_javax.json-api-1.0.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.googlecode.efficient-java-matrix-library_ejml-0.23.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/de.jollyday_jollyday-0.4.7.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/joda-time_joda-time-2.9.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.io7m.xom_xom-1.2.10.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.wordnik_swagger-annotations-1.5.3-M1.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.apache.nifi_nifi-client-dto-0.6.1.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.apache.nifi_nifi-utils-0.6.1.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.apache.nifi_nifi-api-0.6.1.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.sun.jersey_jersey-server-1.2.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.apache.nifi_nifi-site-to-site-client-0.6.1.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.univocity_univocity-parsers-1.5.1.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.apache.commons_commons-csv-1.1.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.tukaani_xz-1.0.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.apache.commons_commons-compress-1.4.1.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.xerial.snappy_snappy-java-1.0.5.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.codehaus.jackson_jackson-core-asl-1.9.13.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.apache.avro_avro-1.7.6.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.scalamacros_quasiquotes_2.10-2.0.1.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.googlecode.javaewah_JavaEWAH-0.6.6.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.codahale.metrics_metrics-core-3.0.2.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/io.netty_netty-3.9.0.Final.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.scala-lang_scala-reflect-2.10.5.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.twitter_jsr166e-1.1.0.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.joda_joda-convert-1.2.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.datastax.cassandra_cassandra-driver-core-2.1.5.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.apache.cassandra_cassandra-clientutil-2.1.5.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.spark-project.spark_unused-1.0.0.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.ankurdave_part_2.10-0.1.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.thoughtworks.paranamer_paranamer-2.8.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.json4s_json4s-scalap_2.10-3.3.0.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.json4s_json4s-ast_2.10-3.3.0.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.json4s_json4s-core_2.10-3.3.0.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.apache.commons_commons-pool2-2.4.2.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/stax_stax-api-1.0.1.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.codehaus.jettison_jettison-1.2.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/xpp3_xpp3_min-1.1.4c.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/xmlpull_xmlpull-1.1.3.1.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.sun.jersey.contribs_jersey-apache-client4-1.8.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.thoughtworks.xstream_xstream-1.4.2.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.sun.jersey_jersey-bundle-1.9.1.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/javax.ws.rs_jsr311-api-1.1.1.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.google.code.findbugs_annotations-2.0.0.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.google.guava_guava-14.0.1.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/commons-lang_commons-lang-2.6.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/commons-configuration_commons-configuration-1.8.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/asm_asm-3.1.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.sonatype.sisu.inject_cglib-2.2.1-v20090111.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/aopalliance_aopalliance-1.0.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/javax.inject_javax.inject-1.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.netflix.eureka_eureka-client-1.1.110.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.netflix.servo_servo-core-0.5.5.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.netflix.archaius_archaius-core-0.5.6.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.google.inject_guice-3.0.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.mockito_mockito-all-1.9.5.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/commons-io_commons-io-2.4.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.apache.commons_commons-math-2.2.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/log4j_log4j-1.2.17.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/redis.clients_jedis-2.8.1.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.netflix.dyno_dyno-contrib-1.4.6.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.netflix.dyno_dyno-core-1.4.6.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.sun.jersey_jersey-core-1.11.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.googlecode.json-simple_json-simple-1.1.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.slf4j_slf4j-log4j12-1.7.21.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.slf4j_slf4j-api-1.7.21.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.google.code.findbugs_jsr305-1.3.9.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.fasterxml.jackson.core_jackson-annotations-2.6.0.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.google.http-client_google-http-client-1.21.0.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.maxmind.db_maxmind-db-1.1.0.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.apache.commons_commons-lang3-3.4.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.amazonaws_aws-java-sdk-1.11.39.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/graphframes_graphframes-0.1.0-spark1.6.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.jblas_jblas-1.2.4.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/edu.stanford.nlp_stanford-corenlp-3.6.0.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.databricks_spark-xml_2.10-0.3.1.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.madhukaraphatak_java-sizeof_2.10-0.1.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.apache.nifi_nifi-spark-receiver-0.6.1.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.databricks_spark-csv_2.10-1.5.0.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.databricks_spark-avro_2.10-2.0.1.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.twitter_algebird-core_2.10-0.11.0.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.datastax.spark_spark-cassandra-connector_2.10-1.4.0.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.elasticsearch_elasticsearch-spark_2.10-2.3.0.BUILD-SNAPSHOT.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.apache.spark_spark-streaming-kafka-assembly_2.10-1.6.1.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/amplab_spark-indexedrdd-0.3.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/org.json4s_json4s-jackson_2.10-3.3.0.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.netflix.dyno_dyno-jedis-1.4.6.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/com.maxmind.geoip2_geoip2-2.5.0.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f/tjhunter_tensorframes-0.2.2-s_2.10.jar',\n",
       " '/tmp/spark-c2dbfbfd-c903-41ba-a65c-5748d479d015/userFiles-54a8e4b0-487a-4dbe-8139-eb34e823b52f',\n",
       " '/root/spark-1.6.1-bin-fluxcapacitor/python',\n",
       " '',\n",
       " '/root/pipeline/myapps/pmml/spark/1.6.1/lib/jpmml_sparkml-1.0rc0-py2.7.egg',\n",
       " '/usr/lib/python3.4',\n",
       " '/usr/lib/python3.4/plat-x86_64-linux-gnu',\n",
       " '/usr/lib/python3.4/lib-dynload',\n",
       " '/usr/local/lib/python3.4/dist-packages',\n",
       " '/usr/lib/python3/dist-packages',\n",
       " '/usr/local/lib/python3.4/dist-packages/IPython/extensions',\n",
       " '/root/.ipython']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export AIRFLOW_HOME='/root/airflow'\r\n",
      "export AKKA_VERSION='2.3.11'\r\n",
      "export ALGEBIRD_VERSION='0.11.0'\r\n",
      "export ANKUR_PART_VERSION='0.1'\r\n",
      "export ATLAS_HOME='/root/atlas-1.4.5'\r\n",
      "export ATLAS_VERSION='1.4.5'\r\n",
      "export BAZEL_HOME='/root/bazel-0.3.0'\r\n",
      "export BAZEL_VERSION='0.3.0'\r\n",
      "export BETTER_FILES_VERSION='2.14.0'\r\n",
      "export CASSANDRA_HOME='/root/apache-cassandra-2.2.6'\r\n",
      "export CASSANDRA_VERSION='2.2.6'\r\n",
      "export CLICOLOR='1'\r\n",
      "export CODAHALE_METRICS_VERSION='3.1.2'\r\n",
      "export COMMONS_DAEMON_VERSION='1.0.15'\r\n",
      "export CONFIG_HOME='/root/pipeline/config'\r\n",
      "export CONFLUENT_HOME='/root/confluent-3.0.0'\r\n",
      "export CONFLUENT_VERSION='3.0.0'\r\n",
      "export DATASETS_HOME='/root/pipeline/datasets'\r\n",
      "export DEV_INSTALL_HOME='/root'\r\n",
      "export DYNOMITE_HOME='/root/dynomite'\r\n",
      "export DYNO_VERSION='1.4.6'\r\n",
      "export ELASTICSEARCH_HOME='/root/elasticsearch-2.3.0'\r\n",
      "export ELASTICSEARCH_VERSION='2.3.0'\r\n",
      "export FINAGLE_VERSION='6.34.0'\r\n",
      "export FLINK_HOME='/root/flink-1.0.0'\r\n",
      "export FLINK_VERSION='1.0.0'\r\n",
      "export GENSORT_VERSION='1.5'\r\n",
      "export GIT_PAGER='cat'\r\n",
      "export GRAPHFRAMES_VERSION='0.1.0-spark1.6'\r\n",
      "export GUAVA_VERSION='14.0.1'\r\n",
      "export HADOOP_HOME='/root/hadoop-2.6.0'\r\n",
      "export HADOOP_USER_CLASSPATH_FIRST='true'\r\n",
      "export HADOOP_VERSION='2.6.0'\r\n",
      "export HIVE_HOME='/root/apache-hive-1.2.1-bin'\r\n",
      "export HIVE_VERSION='1.2.1'\r\n",
      "export HOME='/root'\r\n",
      "export HOSTNAME='pipeline-master-v5-ytpc'\r\n",
      "export HTML_HOME='/root/pipeline/myapps/html'\r\n",
      "export HYSTRIX_DASHBOARD_HOME='/root/hystrix-dashboard-1.5.3'\r\n",
      "export HYSTRIX_DASHBOARD_VERSION='1.5.3'\r\n",
      "export HYSTRIX_VERSION='1.5.3'\r\n",
      "export INDEXEDRDD_VERSION='0.3'\r\n",
      "export JANINO_VERSION='2.7.8'\r\n",
      "export JAVA_HOME='/usr/lib/jvm/java-8-oracle'\r\n",
      "export JAVA_OPTS='-Xmx10G -XX:+CMSClassUnloadingEnabled'\r\n",
      "export JBLAS_VERSION='1.2.4'\r\n",
      "export JEDIS_VERSION='2.7.3'\r\n",
      "export JMETER_HOME='/root/apache-jmeter-3.0'\r\n",
      "export JMETER_VERSION='3.0'\r\n",
      "export JPMML_SPARKML_VERSION='1.0.4'\r\n",
      "export JPY_PARENT_PID='32084'\r\n",
      "export JSON4S_VERSION='3.3.0'\r\n",
      "export KAFKA_CLIENT_VERSION='0.10.0.0'\r\n",
      "export KIBANA_HOME='/root/kibana-4.5.0-linux-x64'\r\n",
      "export KIBANA_VERSION='4.5.0'\r\n",
      "export LESSCLOSE='/usr/bin/lesspipe %s %s'\r\n",
      "export LESSOPEN='| /usr/bin/lesspipe %s'\r\n",
      "export LOGSTASH_HOME='/root/logstash-2.3.0'\r\n",
      "export LOGSTASH_VERSION='2.3.0'\r\n",
      "export LOGS_HOME='/root/pipeline/logs'\r\n",
      "export LS_COLORS='rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arj=01;31:*.taz=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lz=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.axa=00;36:*.oga=00;36:*.spx=00;36:*.xspf=00;36:'\r\n",
      "export MAXMIND_GEOIP_VERSION='2.5.0'\r\n",
      "export MPLBACKEND='module://ipykernel.pylab.backend_inline'\r\n",
      "export MYAPPS_HOME='/root/pipeline/myapps'\r\n",
      "export MYSQL_CONNECTOR_JAR='/usr/share/java/mysql-connector-java.jar'\r\n",
      "export NIFI_HOME='/root/nifi-0.6.1'\r\n",
      "export NIFI_VERSION='0.6.1'\r\n",
      "export OLDPWD='/root/pipeline/myapps'\r\n",
      "export PAGER='cat'\r\n",
      "export PATH='/usr/local/bin:/root/pipeline/myapps/serving:/root/pipeline/myapps/serving/prediction:/root/dynomite:/root/apache-jmeter-3.0/bin:/root/titan-1.0.0-hadoop1/bin:/root/presto-server-0.137/bin:/root/airflow/bin:/root/flink-1.0.0/bin:/root/zeppelin-0.6.0/bin:/root/sbt/bin:/root/nifi-0.6.1/bin:/root/webdis:/root/redis-3.0.5/bin:/root/apache-hive-1.2.1-bin/bin:/root/hadoop-2.6.0/bin:/root/kibana-4.5.0-linux-x64/bin:/root/logstash-2.3.0/bin:/root/elasticsearch-2.3.0/bin:/root/confluent-3.0.0/bin:/root/confluent-3.0.0/bin:/root/spark-1.6.1-bin-fluxcapacitor/tachyon/bin:/root/spark-1.6.1-bin-fluxcapacitor/bin:/root/spark-1.6.1-bin-fluxcapacitor/sbin:/root/apache-cassandra-2.2.6/bin:/root/pipeline/bin/cli:/root/pipeline/bin/cluster:/root/pipeline/bin/docker:/root/pipeline/bin/initial:/root/pipeline/bin/kafka:/root/pipeline/bin/rest:/root/pipeline/bin/service:/root/pipeline/bin/util:/root/bazel-0.3.0/bin:/usr/lib/jvm/java-8-oracle/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\r\n",
      "export PIPELINE_HOME='/root/pipeline'\r\n",
      "export PMML_EVALUATOR_VERSION='1.2.14'\r\n",
      "export PMML_MODEL_METRO_VERSION='1.2.15'\r\n",
      "export PMML_MODEL_VERSION='1.2.15'\r\n",
      "export PRESTO_HOME='/root/presto-server-0.137'\r\n",
      "export PRESTO_VERSION='0.137'\r\n",
      "export PWD='/root/pipeline/myapps/jupyter/Spark/PMML'\r\n",
      "export PYSPARK_SUBMIT_ARGS='--master spark://127.0.0.1:7077 --driver-class-path /root/pipeline/myapps/pmml/spark/1.6.1/lib/jpmml-sparkml-package-1.0-SNAPSHOT.jar,/root/pipeline/myapps/spark/redis/lib/spark-redis_2.10-0.2.0.jar,/usr/share/java/mysql-connector-java.jar,/root/pipeline/myapps/spark/ml/lib/spark-corenlp_2.10-0.1.jar,/root/pipeline/myapps/spark/ml/lib/stanford-corenlp-3.6.0-models.jar,/root/pipeline/myapps/spark/ml/target/scala-2.10/ml_2.10-1.0.jar,/root/pipeline/myapps/spark/sql/target/scala-2.10/sql_2.10-1.0.jar,/root/pipeline/myapps/spark/core/target/scala-2.10/core_2.10-1.0.jar,/root/pipeline/myapps/spark/streaming/target/scala-2.10/streaming_2.10-1.0.jar,/root/pipeline/myapps/serving/spark/target/scala-2.10/spark-serving_2.10-1.0.jar --jars /root/pipeline/myapps/pmml/spark/1.6.1/lib/jpmml-sparkml-package-1.0-SNAPSHOT.jar,/root/pipeline/myapps/spark/redis/lib/spark-redis_2.10-0.2.0.jar,/usr/share/java/mysql-connector-java.jar,/root/pipeline/myapps/spark/ml/lib/spark-corenlp_2.10-0.1.jar,/root/pipeline/myapps/spark/ml/lib/stanford-corenlp-3.6.0-models.jar,/root/pipeline/myapps/spark/ml/target/scala-2.10/ml_2.10-1.0.jar,/root/pipeline/myapps/spark/sql/target/scala-2.10/sql_2.10-1.0.jar,/root/pipeline/myapps/spark/core/target/scala-2.10/core_2.10-1.0.jar,/root/pipeline/myapps/spark/streaming/target/scala-2.10/streaming_2.10-1.0.jar,/root/pipeline/myapps/serving/spark/target/scala-2.10/spark-serving_2.10-1.0.jar --repositories http://dl.bintray.com/spark-packages/maven,https://oss.sonatype.org/content/repositories/snapshots,https://repository.apache.org/content/groups/snapshots --packages tjhunter:tensorframes:0.2.2-s_2.10,com.maxmind.geoip2:geoip2:2.5.0,com.netflix.dyno:dyno-jedis:1.4.6,org.json4s:json4s-jackson_2.10:3.3.0,amplab:spark-indexedrdd:0.3,org.apache.spark:spark-streaming-kafka-assembly_2.10:1.6.1,org.elasticsearch:elasticsearch-spark_2.10:2.3.0.BUILD-SNAPSHOT,com.datastax.spark:spark-cassandra-connector_2.10:1.4.0,redis.clients:jedis:2.7.3,com.twitter:algebird-core_2.10:0.11.0,com.databricks:spark-avro_2.10:2.0.1,com.databricks:spark-csv_2.10:1.5.0,org.apache.nifi:nifi-spark-receiver:0.6.1,com.madhukaraphatak:java-sizeof_2.10:0.1,com.databricks:spark-xml_2.10:0.3.1,edu.stanford.nlp:stanford-corenlp:3.6.0,org.jblas:jblas:1.2.4,graphframes:graphframes:0.1.0-spark1.6,com.amazonaws:aws-java-sdk:1.11.39 pyspark-shell'\r\n",
      "export PYTHONPATH='/root/pipeline/myapps/pmml/spark/1.6.1/lib/jpmml_sparkml-1.0rc0-py2.7.egg'\r\n",
      "export REDIS_HOME='/root/redis-3.0.5'\r\n",
      "export REDIS_VERSION='3.0.5'\r\n",
      "export SBT_ASSEMBLY_PLUGIN_VERSION='0.14.0'\r\n",
      "export SBT_HOME='/root/sbt'\r\n",
      "export SBT_OPTS='-Xmx10G -XX:+CMSClassUnloadingEnabled'\r\n",
      "export SBT_SPARK_PACKAGES_PLUGIN_VERSION='0.2.3'\r\n",
      "export SBT_VERSION='0.13.9'\r\n",
      "export SCALATEST_VERSION='2.2.4'\r\n",
      "export SCALA_MAJOR_VERSION='2.10'\r\n",
      "export SCALA_VERSION='2.10.5'\r\n",
      "export SCRIPTS_HOME='/root/pipeline/bin'\r\n",
      "export SHLVL='2'\r\n",
      "export SPARK_AVRO_CONNECTOR_VERSION='2.0.1'\r\n",
      "export SPARK_CASSANDRA_CONNECTOR_VERSION='1.4.0'\r\n",
      "export SPARK_CSV_CONNECTOR_VERSION='1.5.0'\r\n",
      "export SPARK_ELASTICSEARCH_CONNECTOR_VERSION='2.3.0.BUILD-SNAPSHOT'\r\n",
      "export SPARK_EXAMPLES_JAR='/root/spark-1.6.1-bin-fluxcapacitor/lib/spark-examples-1.6.1-hadoop2.6.0.jar'\r\n",
      "export SPARK_HOME='/root/spark-1.6.1-bin-fluxcapacitor'\r\n",
      "export SPARK_MASTER='spark://127.0.0.1:7077'\r\n",
      "export SPARK_NIFI_CONNECTOR_VERSION='0.6.1'\r\n",
      "export SPARK_OTHER_VERSION='2.0.1-SNAPSHOT'\r\n",
      "export SPARK_REDIS_CONNECTOR_VERSION='0.2.0'\r\n",
      "export SPARK_REPOSITORIES='http://dl.bintray.com/spark-packages/maven,https://oss.sonatype.org/content/repositories/snapshots,https://repository.apache.org/content/groups/snapshots'\r\n",
      "export SPARK_SUBMIT_ARGS='--driver-class-path /root/pipeline/myapps/pmml/spark/1.6.1/lib/jpmml-sparkml-package-1.0-SNAPSHOT.jar,/root/pipeline/myapps/spark/redis/lib/spark-redis_2.10-0.2.0.jar,/usr/share/java/mysql-connector-java.jar,/root/pipeline/myapps/spark/ml/lib/spark-corenlp_2.10-0.1.jar,/root/pipeline/myapps/spark/ml/lib/stanford-corenlp-3.6.0-models.jar,/root/pipeline/myapps/spark/ml/target/scala-2.10/ml_2.10-1.0.jar,/root/pipeline/myapps/spark/sql/target/scala-2.10/sql_2.10-1.0.jar,/root/pipeline/myapps/spark/core/target/scala-2.10/core_2.10-1.0.jar,/root/pipeline/myapps/spark/streaming/target/scala-2.10/streaming_2.10-1.0.jar,/root/pipeline/myapps/serving/spark/target/scala-2.10/spark-serving_2.10-1.0.jar --jars /root/pipeline/myapps/pmml/spark/1.6.1/lib/jpmml-sparkml-package-1.0-SNAPSHOT.jar,/root/pipeline/myapps/spark/redis/lib/spark-redis_2.10-0.2.0.jar,/usr/share/java/mysql-connector-java.jar,/root/pipeline/myapps/spark/ml/lib/spark-corenlp_2.10-0.1.jar,/root/pipeline/myapps/spark/ml/lib/stanford-corenlp-3.6.0-models.jar,/root/pipeline/myapps/spark/ml/target/scala-2.10/ml_2.10-1.0.jar,/root/pipeline/myapps/spark/sql/target/scala-2.10/sql_2.10-1.0.jar,/root/pipeline/myapps/spark/core/target/scala-2.10/core_2.10-1.0.jar,/root/pipeline/myapps/spark/streaming/target/scala-2.10/streaming_2.10-1.0.jar,/root/pipeline/myapps/serving/spark/target/scala-2.10/spark-serving_2.10-1.0.jar --repositories http://dl.bintray.com/spark-packages/maven,https://oss.sonatype.org/content/repositories/snapshots,https://repository.apache.org/content/groups/snapshots --packages tjhunter:tensorframes:0.2.2-s_2.10,com.maxmind.geoip2:geoip2:2.5.0,com.netflix.dyno:dyno-jedis:1.4.6,org.json4s:json4s-jackson_2.10:3.3.0,amplab:spark-indexedrdd:0.3,org.apache.spark:spark-streaming-kafka-assembly_2.10:1.6.1,org.elasticsearch:elasticsearch-spark_2.10:2.3.0.BUILD-SNAPSHOT,com.datastax.spark:spark-cassandra-connector_2.10:1.4.0,redis.clients:jedis:2.7.3,com.twitter:algebird-core_2.10:0.11.0,com.databricks:spark-avro_2.10:2.0.1,com.databricks:spark-csv_2.10:1.5.0,org.apache.nifi:nifi-spark-receiver:0.6.1,com.madhukaraphatak:java-sizeof_2.10:0.1,com.databricks:spark-xml_2.10:0.3.1,edu.stanford.nlp:stanford-corenlp:3.6.0,org.jblas:jblas:1.2.4,graphframes:graphframes:0.1.0-spark1.6,com.amazonaws:aws-java-sdk:1.11.39'\r\n",
      "export SPARK_SUBMIT_JARS='/root/pipeline/myapps/pmml/spark/1.6.1/lib/jpmml-sparkml-package-1.0-SNAPSHOT.jar,/root/pipeline/myapps/spark/redis/lib/spark-redis_2.10-0.2.0.jar,/usr/share/java/mysql-connector-java.jar,/root/pipeline/myapps/spark/ml/lib/spark-corenlp_2.10-0.1.jar,/root/pipeline/myapps/spark/ml/lib/stanford-corenlp-3.6.0-models.jar,/root/pipeline/myapps/spark/ml/target/scala-2.10/ml_2.10-1.0.jar,/root/pipeline/myapps/spark/sql/target/scala-2.10/sql_2.10-1.0.jar,/root/pipeline/myapps/spark/core/target/scala-2.10/core_2.10-1.0.jar,/root/pipeline/myapps/spark/streaming/target/scala-2.10/streaming_2.10-1.0.jar,/root/pipeline/myapps/serving/spark/target/scala-2.10/spark-serving_2.10-1.0.jar'\r\n",
      "export SPARK_SUBMIT_PACKAGES='tjhunter:tensorframes:0.2.2-s_2.10,com.maxmind.geoip2:geoip2:2.5.0,com.netflix.dyno:dyno-jedis:1.4.6,org.json4s:json4s-jackson_2.10:3.3.0,amplab:spark-indexedrdd:0.3,org.apache.spark:spark-streaming-kafka-assembly_2.10:1.6.1,org.elasticsearch:elasticsearch-spark_2.10:2.3.0.BUILD-SNAPSHOT,com.datastax.spark:spark-cassandra-connector_2.10:1.4.0,redis.clients:jedis:2.7.3,com.twitter:algebird-core_2.10:0.11.0,com.databricks:spark-avro_2.10:2.0.1,com.databricks:spark-csv_2.10:1.5.0,org.apache.nifi:nifi-spark-receiver:0.6.1,com.madhukaraphatak:java-sizeof_2.10:0.1,com.databricks:spark-xml_2.10:0.3.1,edu.stanford.nlp:stanford-corenlp:3.6.0,org.jblas:jblas:1.2.4,graphframes:graphframes:0.1.0-spark1.6,com.amazonaws:aws-java-sdk:1.11.39'\r\n",
      "export SPARK_VERSION='1.6.1'\r\n",
      "export SPARK_XML_VERSION='0.3.1'\r\n",
      "export SPRING_BOOT_VERSION='1.3.5.RELEASE'\r\n",
      "export SPRING_CLOUD_VERSION='1.1.2.RELEASE'\r\n",
      "export SPRING_CORE_VERSION='4.3.0.RELEASE'\r\n",
      "export SPRING_PROFILES_ACTIVE='local'\r\n",
      "export STANFORD_CORENLP_VERSION='3.6.0'\r\n",
      "export TACHYON_HOME='/root/spark-1.6.1-bin-fluxcapacitor/tachyon'\r\n",
      "export TENSORFLOW_HOME='/root/tensorflow'\r\n",
      "export TENSORFLOW_SERVING_HOME='/root/serving'\r\n",
      "export TENSORFLOW_SERVING_VERSION='0.4.1'\r\n",
      "export TENSORFLOW_VERSION='0.10.0'\r\n",
      "export TENSORFRAMES_VERSION='0.2.2'\r\n",
      "export TERM='xterm-color'\r\n",
      "export TITAN_HOME='/root/titan-1.0.0-hadoop1'\r\n",
      "export TITAN_VERSION='1.0.0-hadoop1'\r\n",
      "export WEBDIS_HOME='/root/webdis'\r\n",
      "export WORK_HOME='/root/pipeline/work'\r\n",
      "export ZEPPELIN_HOME='/root/zeppelin-0.6.0'\r\n",
      "export ZEPPELIN_VERSION='0.6.0'\r\n",
      "export ZOOKEEPER_HOME='/root/confluent-3.0.0'\r\n",
      "export _='/usr/bin/nohup'\r\n"
     ]
    }
   ],
   "source": [
    "!export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset into Spark Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o37.load.\n: org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/root/datasets/R/census.csv\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:285)\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:228)\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:313)\n\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:199)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)\n\tat scala.Option.getOrElse(Option.scala:120)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:237)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)\n\tat scala.Option.getOrElse(Option.scala:120)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:237)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)\n\tat scala.Option.getOrElse(Option.scala:120)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:237)\n\tat org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1307)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1302)\n\tat org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1342)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n\tat org.apache.spark.rdd.RDD.first(RDD.scala:1341)\n\tat com.databricks.spark.csv.CsvRelation.firstLine$lzycompute(CsvRelation.scala:269)\n\tat com.databricks.spark.csv.CsvRelation.firstLine(CsvRelation.scala:265)\n\tat com.databricks.spark.csv.CsvRelation.inferSchema(CsvRelation.scala:242)\n\tat com.databricks.spark.csv.CsvRelation.<init>(CsvRelation.scala:74)\n\tat com.databricks.spark.csv.DefaultSource.createRelation(DefaultSource.scala:171)\n\tat com.databricks.spark.csv.DefaultSource.createRelation(DefaultSource.scala:44)\n\tat org.apache.spark.sql.execution.datasources.ResolvedDataSource$.apply(ResolvedDataSource.scala:158)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:119)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:109)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\n\tat java.lang.Thread.run(Thread.java:745)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-63ce27ab3d06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqlContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inferSchema\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"header\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/root/datasets/R/census.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/spark-1.6.1-bin-fluxcapacitor/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    135\u001b[0m                     self._jreader.load(self._sqlContext._sc._jvm.PythonUtils.toSeq(path)))\n\u001b[1;32m    136\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/spark-1.6.1-bin-fluxcapacitor/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         return_value = get_return_value(\n\u001b[0;32m--> 813\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/spark-1.6.1-bin-fluxcapacitor/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/spark-1.6.1-bin-fluxcapacitor/python/lib/py4j-0.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    306\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    307\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o37.load.\n: org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/root/datasets/R/census.csv\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:285)\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:228)\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:313)\n\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:199)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)\n\tat scala.Option.getOrElse(Option.scala:120)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:237)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)\n\tat scala.Option.getOrElse(Option.scala:120)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:237)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)\n\tat scala.Option.getOrElse(Option.scala:120)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:237)\n\tat org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1307)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1302)\n\tat org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1342)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n\tat org.apache.spark.rdd.RDD.first(RDD.scala:1341)\n\tat com.databricks.spark.csv.CsvRelation.firstLine$lzycompute(CsvRelation.scala:269)\n\tat com.databricks.spark.csv.CsvRelation.firstLine(CsvRelation.scala:265)\n\tat com.databricks.spark.csv.CsvRelation.inferSchema(CsvRelation.scala:242)\n\tat com.databricks.spark.csv.CsvRelation.<init>(CsvRelation.scala:74)\n\tat com.databricks.spark.csv.DefaultSource.createRelation(DefaultSource.scala:171)\n\tat com.databricks.spark.csv.DefaultSource.createRelation(DefaultSource.scala:44)\n\tat org.apache.spark.sql.execution.datasources.ResolvedDataSource$.apply(ResolvedDataSource.scala:158)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:119)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:109)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\n\tat java.lang.Thread.run(Thread.java:745)\n"
     ]
    }
   ],
   "source": [
    "data = sqlContext.read.format(\"csv\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(\"/root/datasets/R/census.csv\")\n",
    "\n",
    "data.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Decision Tree (Regression) with Spark ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import RFormula\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "formula = RFormula(formula = \"income ~ .\")\n",
    "classifier = DecisionTreeClassifier()\n",
    "pipeline = Pipeline(stages = [formula, classifier])\n",
    "pipelineModel = pipeline.fit(data)\n",
    "\n",
    "pipelineModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Spark ML Model and Pipeline to PMML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from jpmml import toPMMLBytes\n",
    "\n",
    "pmmlBytes = toPMMLBytes(sparkContext, data, pipelineModel)\n",
    "\n",
    "str(pmmlBytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "update_url = 'http://demo.pipeline.io:9040/update-pmml/census'\n",
    "\n",
    "update_headers = {}\n",
    "update_headers['Content-type'] = 'application/json'\n",
    "\n",
    "req = urllib.request.Request(update_url, headers=update_headers, data=pmmlBytes)\n",
    "resp = urllib.request.urlopen(req)\n",
    "\n",
    "print(resp.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "import json\n",
    "\n",
    "evaluate_url = 'http://demo.pipeline.io:9040/evaluate-pmml/census'\n",
    "\n",
    "evaluate_headers = {}\n",
    "evaluate_headers['Content-type'] = 'application/json'\n",
    "input_params = '{\"age\":39,\"workclass\":\"State-gov\",\"education\":\"Bachelors\",\"education_num\":13,\"marital_status\":\"Never-married\",\"occupation\":\"Adm-clerical\",\"relationship\":\"Not-in-family\",\"race\":\"White\",\"sex\":\"Male\",\"capital_gain\":2174,\"capital_loss\":0,\"hours_per_week\":40,\"native_country\":\"United-States\"}' \n",
    "#encoded_input_params = urllib.parse.urlencode(input_params)\n",
    "encoded_input_params = input_params.encode('utf-8')\n",
    "#encoded_input_params = data.encode('utf-8') # data should be bytes\n",
    "\n",
    "req = urllib.request.Request(evaluate_url, headers=evaluate_headers, data=encoded_input_params)\n",
    "resp = urllib.request.urlopen(req)\n",
    "\n",
    "print(resp.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
